{"ID":"20230817161848-5omkzei","Spec":"1","Type":"NodeDocument","Properties":{"id":"20230817161848-5omkzei","title":"性能优化方案","updated":"20230817161848"},"Children":[{"ID":"20230817161849-mpdvun8","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20230817161849-mpdvun8","updated":"20230817161849"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"性能优化方案"}]},{"ID":"20230817161850-8nyz1s5","Type":"NodeParagraph","Properties":{"id":"20230817161850-8nyz1s5","updated":"20230817161850"},"Children":[{"Type":"NodeText","Data":"下面我们通过这几个方式来实现对Spark程序的性能优化"}]},{"ID":"20230817161851-kirqlva","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161851-kirqlva","updated":"20230817161851"},"Children":[{"ID":"20230817161852-b0k2cb1","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161852-b0k2cb1","updated":"20230817161852"},"Children":[{"ID":"20230817161853-2jo8dsx","Type":"NodeParagraph","Properties":{"id":"20230817161853-2jo8dsx","updated":"20230817161853"},"Children":[{"Type":"NodeText","Data":"高性能序列化类库"}]}]},{"ID":"20230817161854-idmsjjx","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161854-idmsjjx","updated":"20230817161854"},"Children":[{"ID":"20230817161855-5k9cspi","Type":"NodeParagraph","Properties":{"id":"20230817161855-5k9cspi","updated":"20230817161855"},"Children":[{"Type":"NodeText","Data":"持久化或者checkpoint"}]}]},{"ID":"20230817161856-3mbooh0","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161856-3mbooh0","updated":"20230817161856"},"Children":[{"ID":"20230817161857-ww6fbrd","Type":"NodeParagraph","Properties":{"id":"20230817161857-ww6fbrd","updated":"20230817161857"},"Children":[{"Type":"NodeText","Data":"JVM垃圾回收调优"}]}]},{"ID":"20230817161858-3lytrzv","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161858-3lytrzv","updated":"20230817161858"},"Children":[{"ID":"20230817161859-191pdaa","Type":"NodeParagraph","Properties":{"id":"20230817161859-191pdaa","updated":"20230817161859"},"Children":[{"Type":"NodeText","Data":"提高并行度"}]}]},{"ID":"20230817161860-ascnqu5","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161860-ascnqu5","updated":"20230817161860"},"Children":[{"ID":"20230817161861-tkgq2j1","Type":"NodeParagraph","Properties":{"id":"20230817161861-tkgq2j1","updated":"20230817161861"},"Children":[{"Type":"NodeText","Data":"数据本地化"}]}]},{"ID":"20230817161862-ats2txy","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161862-ats2txy","updated":"20230817161862"},"Children":[{"ID":"20230817161863-r6caztx","Type":"NodeParagraph","Properties":{"id":"20230817161863-r6caztx","updated":"20230817161863"},"Children":[{"Type":"NodeText","Data":"算子优化"}]}]}]},{"ID":"20230817161864-q4jp6lu","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20230817161864-q4jp6lu","updated":"20230817161864"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"高性能序列化类库"}]},{"ID":"20230817161865-ovgg2lb","Type":"NodeParagraph","Properties":{"id":"20230817161865-ovgg2lb","updated":"20230817161865"},"Children":[{"Type":"NodeText","Data":"在任何分布式系统中，序列化都是扮演着一个重要的角色的。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"如果使用的序列化技术，在执行序列化操作的时候很慢，或者是序列化后的数据还是很大，那么会让分布式应用程序的性能下降很多。所以，进行Spark性能优化的第一步，就是进行序列化的性能优化。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"Spark默认会在一些地方对数据进行序列化，如果我们的算子函数使用到了外部的数据（比如Java中的自定义类型），那么也需要让其可序列化，否则程序在执行的时候是会报错的，提示没有实现序列化，这个一定要注意。"}]},{"ID":"20230817161866-c1gj9nt","Type":"NodeParagraph","Properties":{"id":"20230817161866-c1gj9nt","updated":"20230817161866"},"Children":[{"Type":"NodeText","Data":"原因是这样的："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"因为Spark的初始化工作是在Driver进程中进行的，但是实际执行是在Worker节点的Executor进程中进行的；当Executor端需要用到Driver端封装的对象时，就需要把Driver端的对象通过序列化传输到Executor端，这个对象就需要实现序列化。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"否则会报错，提示对象没有实现序列化"}]},{"ID":"20230817161867-dsgunws","Type":"NodeBlockquote","Properties":{"id":"20230817161867-dsgunws","updated":"20230817161867"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161868-ngcrxcb","Type":"NodeParagraph","Properties":{"id":"20230817161868-ngcrxcb","updated":"20230817161868"},"Children":[{"Type":"NodeText","Data":"注意了，其实遇到这种没有实现序列化的对象，解决方法有两种"}]}]},{"ID":"20230817161869-olix6y3","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20230817161869-olix6y3","updated":"20230817161869"},"Children":[{"ID":"20230817161870-y5h9o25","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20230817161870-y5h9o25","updated":"20230817161870"},"Children":[{"ID":"20230817161871-thaypj8","Type":"NodeParagraph","Properties":{"id":"20230817161871-thaypj8","updated":"20230817161871"},"Children":[{"Type":"NodeText","Data":"如果此对象可以支持序列化，则将其实现Serializable接口，让它支持序列化"}]}]},{"ID":"20230817161872-xft0agq","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20230817161872-xft0agq","updated":"20230817161872"},"Children":[{"ID":"20230817161873-hkywkl5","Type":"NodeParagraph","Properties":{"id":"20230817161873-hkywkl5","updated":"20230817161873"},"Children":[{"Type":"NodeText","Data":"如果此对象不支持序列化，针对一些数据库连接之类的对象，这种对象是不支持序列化的，所以可以把这个代码放到算子内部，这样就不会通过driver端传过去了，它会直接在executor中执行。"}]}]}]},{"ID":"20230817161874-ognbm1j","Type":"NodeParagraph","Properties":{"id":"20230817161874-ognbm1j","updated":"20230817161874"},"Children":[{"Type":"NodeText","Data":"Spark对于序列化的便捷性和性能进行了一个取舍和权衡。默认情况下，Spark倾向于序列化的便捷性，使用了Java自身提供的序列化机制——基于"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"ObjectInputStream"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"ObjectOutputStream"},{"Type":"NodeText","Data":"的序列化机制，因为这种方式是Java原生提供的，使用起来比较方便，"}]},{"ID":"20230817161875-08h50jd","Type":"NodeParagraph","Properties":{"id":"20230817161875-08h50jd","updated":"20230817161875"},"Children":[{"Type":"NodeText","Data":"但是Java序列化机制的性能并不高。序列化的速度相对较慢，而且序列化以后的数据，相对来说还是比较大，比较占空间。所以，如果你的Spark应用程序对内存很敏感，那默认的Java序列化机制并不是最好的选择。"}]},{"ID":"20230817161876-dadtqh5","Type":"NodeParagraph","Properties":{"id":"20230817161876-dadtqh5","updated":"20230817161876"},"Children":[{"Type":"NodeText","Data":"Spark实际上提供了两种序列化机制："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"Java序列化机制和Kryo序列化机制"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"Spark只是默认使用了java这种序列化机制"}]},{"ID":"20230817161877-v3barg2","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161877-v3barg2","updated":"20230817161877"},"Children":[{"ID":"20230817161878-xdeyuhl","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161878-xdeyuhl","updated":"20230817161878"},"Children":[{"ID":"20230817161879-rl1oimm","Type":"NodeParagraph","Properties":{"id":"20230817161879-rl1oimm","updated":"20230817161879"},"Children":[{"Type":"NodeText","Data":"Java序列化机制：默认情况下，Spark使用Java自身的ObjectInputStream和ObjectOutputStream机制进行对象的序列化。只要你的类实现了Serializable接口，那么都是可以序列化的。Java序列化机制的速度比较慢，而且序列化后的数据占用的内存空间比较大，这是它的缺点"}]}]},{"ID":"20230817161880-hmefly1","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161880-hmefly1","updated":"20230817161880"},"Children":[{"ID":"20230817161881-w118agl","Type":"NodeParagraph","Properties":{"id":"20230817161881-w118agl","updated":"20230817161881"},"Children":[{"Type":"NodeText","Data":"Kryo序列化机制：Spark也支持使用Kryo序列化。Kryo序列化机制比Java序列化机制更快，而且序列化后的数据占用的空间更小，通常比Java序列化的数据占用的空间要小10倍左右。"}]}]}]},{"ID":"20230817161882-14xux45","Type":"NodeBlockquote","Properties":{"id":"20230817161882-14xux45","updated":"20230817161882"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161883-4r72lb1","Type":"NodeParagraph","Properties":{"id":"20230817161883-4r72lb1","updated":"20230817161883"},"Children":[{"Type":"NodeText","Data":"Kryo序列化机制之所以不是默认序列化机制的原因："}]}]},{"ID":"20230817161884-0utqdek","Type":"NodeParagraph","Properties":{"id":"20230817161884-0utqdek","updated":"20230817161884"},"Children":[{"Type":"NodeText","Data":"第一点：因为有些类型虽然实现了Seriralizable接口，但是它也不一定能够被Kryo进行序列化；"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"第二点：如果你要得到最佳的性能，Kryo还要求你在Spark应用程序中，对所有你需要序列化的类型都进行手工注册，这样就比较麻烦了"}]},{"ID":"20230817161885-b88cms4","Type":"NodeParagraph","Properties":{"id":"20230817161885-b88cms4","updated":"20230817161885"},"Children":[{"Type":"NodeText","Data":"如果要使用Kryo序列化机制"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"首先要用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"SparkConf"},{"Type":"NodeText","Data":"设置"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"spark.serializer"},{"Type":"NodeText","Data":"的值为"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"org.apache.spark.serializer.KryoSerializer"},{"Type":"NodeText","Data":"，就是将Spark的序列化器设置为"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"KryoSerializer"},{"Type":"NodeText","Data":"。这样，Spark在进行序列化时，就会使用Kryo进行序列化了。"}]},{"ID":"20230817161886-r89z1qh","Type":"NodeParagraph","Properties":{"id":"20230817161886-r89z1qh","updated":"20230817161886"},"Children":[{"Type":"NodeText","Data":"使用Kryo时针对需要序列化的类，需要预先进行注册，这样才能获得最佳性能——如果不注册的话，Kryo也能正常工作，只是Kryo必须时刻保存类型的全类名，反而占用不少内存。"}]},{"ID":"20230817161887-ss6rohk","Type":"NodeParagraph","Properties":{"id":"20230817161887-ss6rohk","updated":"20230817161887"},"Children":[{"Type":"NodeText","Data":"Spark默认对Scala中常用的类型在Kryo中做了注册，但是，如果在自己的算子中，使用了外部的自定义类型的对象，那么还是需要对其进行注册。"}]},{"ID":"20230817161888-5y413ot","Type":"NodeParagraph","Properties":{"id":"20230817161888-5y413ot","updated":"20230817161888"},"Children":[{"Type":"NodeText","Data":"注册自定义的数据类型格式："}]},{"ID":"20230817161889-5mkf72l","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817161889-5mkf72l","updated":"20230817161889"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"conf.registerKryoClasses(...)\n代码块1\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20230817161890-hxdtue0","Type":"NodeBlockquote","Properties":{"id":"20230817161890-hxdtue0","updated":"20230817161890"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161891-y8mho8b","Type":"NodeParagraph","Properties":{"id":"20230817161891-y8mho8b","updated":"20230817161891"},"Children":[{"Type":"NodeText","Data":"注意：如果要序列化的自定义的类型，字段特别多，此时就需要对Kryo本身进行优化，因为Kryo内部的缓存可能不够存放那么大的class对象"}]}]},{"ID":"20230817161892-irkrl4e","Type":"NodeParagraph","Properties":{"id":"20230817161892-irkrl4e","updated":"20230817161892"},"Children":[{"Type":"NodeText","Data":"需要调用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"SparkConf.set()"},{"Type":"NodeText","Data":"方法，设置"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"spark.kryoserializer.buffer.mb"},{"Type":"NodeText","Data":"参数的值，将其调大，默认值为"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"2"},{"Type":"NodeText","Data":"，单位是"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"MB"},{"Type":"NodeText","Data":"，也就是说最大能缓存"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"2M"},{"Type":"NodeText","Data":"的对象，然后进行序列化。可以在必要时将其调大。"}]},{"ID":"20230817161893-j68p1is","Type":"NodeBlockquote","Properties":{"id":"20230817161893-j68p1is","updated":"20230817161893"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161894-5dno5ss","Type":"NodeParagraph","Properties":{"id":"20230817161894-5dno5ss","updated":"20230817161894"},"Children":[{"Type":"NodeText","Data":"什么场景下适合使用Kryo序列化？"}]}]},{"ID":"20230817161895-htv6whj","Type":"NodeParagraph","Properties":{"id":"20230817161895-htv6whj","updated":"20230817161895"},"Children":[{"Type":"NodeText","Data":"一般是针对一些自定义的对象，例如我们自己定义了一个对象，这个对象里面包含了几十M，或者上百M的数据，然后在算子函数内部，使用到了这个外部的大对象"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"如果默认情况下，让Spark用java序列化机制来序列化这种外部的大对象，那么就会导致序列化速度比较慢，并且序列化以后的数据还是比较大。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"所以，在这种情况下，比较适合使用Kryo序列化类库，来对外部的大对象进行序列化，提高序列化速度，减少序列化后的内存空间占用。"}]},{"ID":"20230817161896-hzdvqxm","Type":"NodeParagraph","Properties":{"id":"20230817161896-hzdvqxm","updated":"20230817161896"},"Children":[{"Type":"NodeText","Data":"用代码实现一个案例："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"scala代码如下："}]},{"ID":"20230817161897-2hbi1bf","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817161897-2hbi1bf","updated":"20230817161897"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"package com.imooc.scala\n\nimport com.esotericsoftware.kryo.Kryo\nimport org.apache.spark.serializer.KryoRegistrator\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.{SparkConf, SparkContext}\n\n/**\n * 需求：Kryo序列化的使用\n * Created by xuwei\n */\nobject KryoSerScala {\n\n  def main(args: Array[String]): Unit = {\n    val conf = new SparkConf()\n    conf.setAppName(\"KryoSerScala\")\n      .setMaster(\"local\")\n      //指定使用kryo序列化机制，注意：如果使用了registerKryoClasses，其实这一行设置是可以省略的\n      .set(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n      .registerKryoClasses(Array(classOf[Person]))//注册自定义的数据类型\n    val sc = new SparkContext(conf)\n\n    val dataRDD = sc.parallelize(Array(\"hello you\",\"hello me\"))\n    val wordsRDD = dataRDD.flatMap(_.split(\" \"))\n    val personRDD = wordsRDD.map(word=\u003ePerson(word,18)).persist(StorageLevel.MEMORY_ONLY_SER)\n    personRDD.foreach(println(_))\n\n      //while循环是为了保证程序不结束，方便在本地查看4040页面中的storage信息\n    while (true) {\n      ;\n    }\n  }\n\n}\ncase class Person(name: String,age: Int) extends Serializable\n代码块1234567891011121314151617181920212223242526272829303132333435\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20230817161898-kdr0a4o","Type":"NodeParagraph","Properties":{"id":"20230817161898-kdr0a4o","updated":"20230817161898"},"Children":[{"Type":"NodeText","Data":"执行任务，然后访问localhost的4040界面"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"在界面中可以看到cache的数据大小是"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"31"},{"Type":"NodeText","Data":"字节。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"图片描述","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://img.mukewang.com/wiki/5f5649eb09027c1112650341.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817161899-lc6yr2b","Type":"NodeParagraph","Properties":{"id":"20230817161899-lc6yr2b","updated":"20230817161899"},"Children":[{"Type":"NodeText","Data":"那我们把kryo序列化设置去掉，使用默认的java序列化看一下效果"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"修改代码，注释掉这两行代码即可"}]},{"ID":"20230817161900-4nk9cfi","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817161900-4nk9cfi","updated":"20230817161900"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"//.set(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n//.registerKryoClasses(Array(classOf[Person]))\n代码块12\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20230817161901-v94vakm","Type":"NodeParagraph","Properties":{"id":"20230817161901-v94vakm","updated":"20230817161901"},"Children":[{"Type":"NodeText","Data":"运行任务，再访问4040界面"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"发现此时占用的内存空间是"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"138"},{"Type":"NodeText","Data":"字节，比使用kryo的方式内存空间多占用了将近5倍。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"所以从这可以看出来，使用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"kryo"},{"Type":"NodeText","Data":"序列化方式对内存的占用会降低很多。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"图片描述","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://img.mukewang.com/wiki/5f564a1b09a53a5412670318.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817161902-k0xfsx4","Type":"NodeBlockquote","Properties":{"id":"20230817161902-k0xfsx4","updated":"20230817161902"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161903-4g2icj8","Type":"NodeParagraph","Properties":{"id":"20230817161903-4g2icj8","updated":"20230817161903"},"Children":[{"Type":"NodeText","Data":"注意：如果我们只是将spark的序列化机制改为了kryo序列化，但是没有对使用到的自定义类型手工进行注册，那么此时内存的占用会介于前面两种情况之间"}]}]},{"ID":"20230817161904-8h4hwg0","Type":"NodeParagraph","Properties":{"id":"20230817161904-8h4hwg0","updated":"20230817161904"},"Children":[{"Type":"NodeText","Data":"修改代码，只注释掉registerKryoClasses这一行代码"}]},{"ID":"20230817161905-pj7vbtl","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817161905-pj7vbtl","updated":"20230817161905"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":".set(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n//.registerKryoClasses(Array(classOf[Person]))//注册自定义的数据类型\n代码块12\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20230817161906-apapzb7","Type":"NodeParagraph","Properties":{"id":"20230817161906-apapzb7","updated":"20230817161906"},"Children":[{"Type":"NodeText","Data":"运行任务，再访问4040界面"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"发现此时的内存占用为"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"123"},{"Type":"NodeText","Data":"字节，介于前面的"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"31"},{"Type":"NodeText","Data":"字节和"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"138"},{"Type":"NodeText","Data":"字节之间。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"所以从这可以看出来，在使用kryo序列化的时候，针对自定义的类型最好是手工注册一下，否则就算开启了kryo序列化，性能的提升也是有限的。"}]},{"ID":"20230817161907-3no3dep","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20230817161907-3no3dep","updated":"20230817161907"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"持久化或者checkpoint"}]},{"ID":"20230817161908-infls6s","Type":"NodeParagraph","Properties":{"id":"20230817161908-infls6s","updated":"20230817161908"},"Children":[{"Type":"NodeText","Data":"针对程序中多次被transformation或者action操作的RDD进行持久化操作，避免对一个RDD反复进行计算，再进一步优化，使用Kryo序列化的持久化级别，减少内存占用"}]},{"ID":"20230817161909-gdwbw0d","Type":"NodeParagraph","Properties":{"id":"20230817161909-gdwbw0d","updated":"20230817161909"},"Children":[{"Type":"NodeText","Data":"为了保证RDD持久化数据在可能丢失的情况下还能实现高可靠，则需要对RDD执行Checkpoint操作"}]},{"ID":"20230817161910-y2kcrdk","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20230817161910-y2kcrdk","updated":"20230817161910"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"JVM垃圾回收调优"}]},{"ID":"20230817161911-6i905av","Type":"NodeParagraph","Properties":{"id":"20230817161911-6i905av","updated":"20230817161911"},"Children":[{"Type":"NodeText","Data":"由于Spark是基于内存的计算引擎，RDD缓存的数据，以及算子执行期间创建的对象都是放在内存中的，所以针对Spark任务如果内存设置不合理会导致大部分时间都消耗在垃圾回收上"}]},{"ID":"20230817161912-ezcu0fj","Type":"NodeParagraph","Properties":{"id":"20230817161912-ezcu0fj","updated":"20230817161912"},"Children":[{"Type":"NodeText","Data":"对于垃圾回收来说，最重要的就是调节RDD缓存占用的内存空间，和算子执行时创建的对象占用的内存空间的比例。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"默认情况下，Spark使用每个"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"executor 60%"},{"Type":"NodeText","Data":"的内存空间来缓存RDD，那么只有"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"40%"},{"Type":"NodeText","Data":"的内存空间来存放算子执行期间创建的对象"}]},{"ID":"20230817161913-yqj6m6q","Type":"NodeParagraph","Properties":{"id":"20230817161913-yqj6m6q","updated":"20230817161913"},"Children":[{"Type":"NodeText","Data":"在这种情况下，可能由于内存空间的不足，并且算子对应的task任务在运行时创建的对象过大，那么一旦发现"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"40%"},{"Type":"NodeText","Data":"的内存空间不够用了，就会触发Java虚拟机的垃圾回收操作。因此在极端情况下，垃圾回收操作可能会被频繁触发。"}]},{"ID":"20230817161914-o1awqnw","Type":"NodeParagraph","Properties":{"id":"20230817161914-o1awqnw","updated":"20230817161914"},"Children":[{"Type":"NodeText","Data":"在这种情况下，如果发现垃圾回收频繁发生。那么就需要对这个比例进行调优了，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"spark.storage.memoryFraction"},{"Type":"NodeText","Data":"参数的值默认是"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"0.6"},{"Type":"NodeText","Data":"。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"使用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"SparkConf().set(\u0026quot;spark.storage.memoryFraction\u0026quot;, \u0026quot;0.5\u0026quot;)"},{"Type":"NodeText","Data":"可以进行修改，就是将RDD缓存占用内存空间的比例降低为"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"50%"},{"Type":"NodeText","Data":"，从而提供更多的内存空间来保存task运行时创建的对象。"}]},{"ID":"20230817161915-snycpkt","Type":"NodeParagraph","Properties":{"id":"20230817161915-snycpkt","updated":"20230817161915"},"Children":[{"Type":"NodeText","Data":"因此，对于RDD持久化而言，完全可以使用Kryo序列化，加上降低其executor内存占比的方式，来减少其内存消耗。给task提供更多的内存，从而避免task在执行时频繁触发垃圾回收。"}]},{"ID":"20230817161916-j6gmpo4","Type":"NodeParagraph","Properties":{"id":"20230817161916-j6gmpo4","updated":"20230817161916"},"Children":[{"Type":"NodeText","Data":"我们可以对task的垃圾回收进行监测，在spark的任务执行界面，可以查看每个task执行消耗的时间，以及task gc消耗的时间。"}]},{"ID":"20230817161917-2vu9d46","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20230817161917-2vu9d46","updated":"20230817161917"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"java GC"}]},{"ID":"20230817161918-kzu9rwc","Type":"NodeParagraph","Properties":{"id":"20230817161918-kzu9rwc","updated":"20230817161918"},"Children":[{"Type":"NodeText","Data":"Java堆空间被划分成了两块空间：一个是年轻代，一个是老年代。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"年轻代放的是短时间存活的对象"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"老年代放的是长时间存活的对象。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"年轻代又被划分了三块空间，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"Eden、Survivor1、Survivor2"}]},{"ID":"20230817161919-l83e4u6","Type":"NodeParagraph","Properties":{"id":"20230817161919-l83e4u6","updated":"20230817161919"},"Children":[{"Type":"NodeText","Data":"来看一下这个内存划分比例图"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"图片描述","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://img.mukewang.com/wiki/5f564abf0999298317370398.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817161920-o7ekdy7","Type":"NodeBlockquote","Properties":{"id":"20230817161920-o7ekdy7","updated":"20230817161920"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161921-qh6ggto","Type":"NodeParagraph","Properties":{"id":"20230817161921-qh6ggto","updated":"20230817161921"},"Children":[{"Type":"NodeText","Data":"年轻代占堆内存的1/3，老年代占堆内存的2/3"}]}]},{"ID":"20230817161922-1dh5vob","Type":"NodeParagraph","Properties":{"id":"20230817161922-1dh5vob","updated":"20230817161922"},"Children":[{"Type":"NodeText","Data":"其中年轻代又被划分了三块，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"Eden，Survivor1，Survivor2"},{"Type":"NodeText","Data":"的比例为"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"8:1:1"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"Eden区域和Survivor1区域用于存放对象，Survivor2区域备用。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"我们创建的对象，首先会放入Eden区域，如果Eden区域满了，那么就会触发一次Minor GC，进行年轻代的垃圾回收(其实就是回收Eden区域内没有人使用的对象)，然后将存活的对象存入Survivor1区域，再创建对象的时候继续放入Eden区域。第二次Eden区域满了，那么Eden和Survivor1区域中存活的对象，会一块被移动到Survivor2区域中。然后Survivor1和Survivor2的角色调换，Survivor1变成了备用。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"当第三次Eden区域再满了的时候，Eden和Survivor2区域中存活的对象，会一块被移动到Survivor1区域中，按照这个规律进行循环"}]},{"ID":"20230817161923-xjju0x5","Type":"NodeParagraph","Properties":{"id":"20230817161923-xjju0x5","updated":"20230817161923"},"Children":[{"Type":"NodeText","Data":"如果一个对象，在年轻代中，撑过了多次垃圾回收(默认是15次)，都没有被回收掉，那么会被认为是长时间存活的，此时就会被移入老年代。此外，如果在将Eden和Survivor1中的存活对象，尝试放入Survivor2中时，发现Survivor2放满了，那么会直接放入老年代。此时就出现了，短时间存活的对象，也会进入老年代的问题。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"如果老年代的空间满了，那么就会触发Full GC，进行老年代的垃圾回收操作，如果执行Full GC也释放不了内存空间，就会报内存溢出的错误了。"}]},{"ID":"20230817161924-1m9eu3c","Type":"NodeBlockquote","Properties":{"id":"20230817161924-1m9eu3c","updated":"20230817161924"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161925-vap80s2","Type":"NodeParagraph","Properties":{"id":"20230817161925-vap80s2","updated":"20230817161925"},"Children":[{"Type":"NodeText","Data":"注意了，Full GC是一个重量级的垃圾回收，Full GC执行的时候，程序是处于暂停状态的，这样会非常影响性能。"}]}]},{"ID":"20230817161926-b9ytm7q","Type":"NodeParagraph","Properties":{"id":"20230817161926-b9ytm7q","updated":"20230817161926"},"Children":[{"Type":"NodeText","Data":"Spark中，垃圾回收调优的目标就是，只有真正长时间存活的对象，才能进入老年代，短时间存活的对象，只能呆在年轻代。不能因为某个Survivor区域空间不够，在Minor GC时，就进入了老年代，从而造成短时间存活的对象，长期呆在老年代中占据了空间，这样Full GC时要回收大量的短时间存活的对象，导致Full GC速度缓慢。"}]},{"ID":"20230817161927-lmm56t3","Type":"NodeParagraph","Properties":{"id":"20230817161927-lmm56t3","updated":"20230817161927"},"Children":[{"Type":"NodeText","Data":"如果发现，在task执行期间，大量full gc发生了，那么说明，年轻代的Eden区域，给的空间不够大。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"此时可以执行一些操作来优化垃圾回收行为"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"1：最直接的就是提高Executor的内存"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"在spark-submit中通过参数指定executor的内存"}]},{"ID":"20230817161928-uhmicj0","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817161928-uhmicj0","updated":"20230817161928"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"--executor-memory 1G \n代码块1\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20230817161929-sgxwj5l","Type":"NodeParagraph","Properties":{"id":"20230817161929-sgxwj5l","updated":"20230817161929"},"Children":[{"Type":"NodeText","Data":"2：调整Eden与s1和s2的比值【一般情况下不建议调整这块的比值】"}]}]}