{"ID":"20230817162004-7nd33ae","Spec":"1","Type":"NodeDocument","Properties":{"id":"20230817162004-7nd33ae","title":"MapReduce之数据倾斜问题","updated":"20230817162004"},"Children":[{"ID":"20230817162005-nsykaij","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817162005-nsykaij","updated":"20230817162005"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"MapReduce之数据倾斜问题"}]},{"ID":"20230817162006-uk93y58","Type":"NodeParagraph","Properties":{"id":"20230817162006-uk93y58","updated":"20230817162006"},"Children":[{"Type":"NodeText","Data":"问题背景：当我们需要提高mapreduce的执行效率时 在reduce端可以通过增减reducetask数量来提高效率 但如果一个文件中的某个数据过度倾斜 会导致执行这个分区的reduce任务速度依然很慢 从而拖累全局的一个执行时间"}]},{"ID":"20230817162007-qesusp8","Type":"NodeParagraph","Properties":{"id":"20230817162007-qesusp8","updated":"20230817162007"},"Children":[{"Type":"NodeText","Data":"分区函数："}]},{"ID":"20230817162008-lx3uuxc","Type":"NodeParagraph","Properties":{"id":"20230817162008-lx3uuxc","updated":"20230817162008"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"分区函数","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"C:\\Users\\HHH\\Desktop\\分区函数.png","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817162009-eq06e0z","Type":"NodeParagraph","Properties":{"id":"20230817162009-eq06e0z","updated":"20230817162009"},"Children":[{"Type":"NodeText","Data":"解决方案：可以从分区函数看出 我们可以将map阶段处理好的v2进行打散 比如在key2后面加一些随机数字 从而导致key的哈希值不一样 最后分区也不会集中在一个reducetask中"}]}]}