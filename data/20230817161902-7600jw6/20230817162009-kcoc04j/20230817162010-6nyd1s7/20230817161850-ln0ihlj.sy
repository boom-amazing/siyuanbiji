{"ID":"20230817161850-ln0ihlj","Spec":"1","Type":"NodeDocument","Properties":{"id":"20230817161850-ln0ihlj","title":"HBase架构详解","updated":"20230817161850"},"Children":[{"ID":"20230817161851-xduaxxz","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20230817161851-xduaxxz","updated":"20230817161851"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Hbase架构详解"}]},{"ID":"20230817161852-1c55swn","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20230817161852-1c55swn","updated":"20230817161852"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"###### ","Properties":{"id":""}},{"Type":"NodeText","Data":"hbase架构图"}]},{"ID":"20230817161853-d8oge9x","Type":"NodeParagraph","Properties":{"id":"20230817161853-d8oge9x","updated":"20230817161853"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"hbase架构","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"C:\\Users\\HHH\\Desktop\\hbase架构.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817161854-jbbltna","Type":"NodeParagraph","Properties":{"id":"20230817161854-jbbltna","updated":"20230817161854"},"Children":[{"Type":"NodeText","Data":"图中虚线下面是HDFS部分 上面是HBase的部分"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"Client(客户端)想要连接HBase的时候，需要先连接Zookeeper。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"首先会找Zookeeper中 /hbase/meta-region-server这个节点，这个节点里面保存了HBase中meta表的数据（Region）所在的Regionserve节点信息。"}]},{"ID":"20230817161855-c9gqu8b","Type":"NodeParagraph","Properties":{"id":"20230817161855-c9gqu8b","updated":"20230817161855"},"Children":[{"Type":"NodeText","Data":"客户端到Zookeeper中找到这个信息以后，就把这个信息加载到缓存中了，这样就不用每次都去重新加载了"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"meta表中存储了所有表的相关信息，可能会有很多，都加载到内存的话可能会扛不住的，所以客户端并不会加载meta表中的所有数据，只会把meta表中我们目前需要的相关数据加载到内存。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"meta表里面存储的有HBase中所有表对应的RegionServer节点信息"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"scan ‘hbase:meta’ 可以看到这个meta表里面的详细信息。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"所以客户端这个时候其实就可以获取到表对应RegionServer的IP和端口信息了，通过RPC机制就可以通信了。"}]},{"ID":"20230817161856-3bs0ooa","Type":"NodeParagraph","Properties":{"id":"20230817161856-3bs0ooa","updated":"20230817161856"},"Children":[{"Type":"NodeText","Data":"Regionserver内部"}]},{"ID":"20230817161857-x85dydx","Type":"NodeParagraph","Properties":{"id":"20230817161857-x85dydx","updated":"20230817161857"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"Hregionserver","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"C:\\Users\\HHH\\Desktop\\Hregionserver.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817161858-wz9r2mp","Type":"NodeParagraph","Properties":{"id":"20230817161858-wz9r2mp","updated":"20230817161858"},"Children":[{"Type":"NodeText","Data":"HRegionServer里面有2块内容，一个是HLog ，另一个是HRegion(其实就是我们前面分析的Region，是同一个意思，Region是HRegion的简称)。"}]},{"ID":"20230817161859-b6tyb21","Type":"NodeParagraph","Properties":{"id":"20230817161859-b6tyb21","updated":"20230817161859"},"Children":[{"Type":"NodeText","Data":"在一个HRegionServer里面，HLog只有一个，HRegion会有多个，这个框后面是有三个点，表示是多个的意思。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"HLog是负责记录日志的，针对这个HRegionServer中的所有写操作，包括put、delete等操作，只要是会对数据产生变化的操作，都会记录到这个日志中，再把数据写到对应的HRegion中。"}]},{"ID":"20230817161860-1jyignl","Type":"NodeParagraph","Properties":{"id":"20230817161860-1jyignl","updated":"20230817161860"},"Children":[{"Type":"NodeText","Data":"HRegion就是负责存储实际数据了。"}]},{"ID":"20230817161861-w7ht4a8","Type":"NodeParagraph","Properties":{"id":"20230817161861-w7ht4a8","updated":"20230817161861"},"Children":[{"Type":"NodeText","Data":"看一下HRegion内部："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"HRejion","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"C:\\Users\\HHH\\Desktop\\HRejion.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"每一个Store对应一个列族，所以一个HRegion里面可能会有多个Store。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"向HRegionserver中写数据的时候，会先写HLog，然后在把数据写入HRegion的时候，会根据指定的列族信息写入到不同的Store里面，我们之前在向表中put数据的时候，表名和列族名称都是必须要指定的。"}]},{"ID":"20230817161862-38t6oys","Type":"NodeParagraph","Properties":{"id":"20230817161862-38t6oys","updated":"20230817161862"},"Children":[{"Type":"NodeText","Data":"Store里面包含两部分：MemStore 和 StoreFile。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"用户写入的数据首先会放入MemStore【基于内存的Store】里面，当这个MemStore写满了以后，会把数据持久化到StoreFile中，每一次内存满了持久化的时候都会生成一个StoreFile，StoreFile底层对应的是一个HFile文件。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"HFile文件会通过下面的DFS Client写入到HDFS中。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"最终HLog和HFile都是用DFS Client写入到HDFS中的。"}]},{"ID":"20230817161863-w8hn7ks","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161863-w8hn7ks","updated":"20230817161863"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"HBase物理存储模型"}]},{"ID":"20230817161864-tn2ik0y","Type":"NodeParagraph","Properties":{"id":"20230817161864-tn2ik0y","updated":"20230817161864"},"Children":[{"Type":"NodeText","Data":"HBase中表的数据是存储在Region中的，表中的数据会越来越多，Region就会分裂，分裂出来的多个Region会分布到多个节点上面，因为单台机器的存储能力是有限的，这样对后期数据并行读取也有好处，有利于扩展。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"这样就可以保证一个表能存储海量数据，存放Region的服务器称之为Region Server。"}]},{"ID":"20230817161865-np2pgiw","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161865-np2pgiw","updated":"20230817161865"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"WAL(Write-Ahead Logging)预写日志系统"}]},{"ID":"20230817161866-bzfw5rn","Type":"NodeParagraph","Properties":{"id":"20230817161866-bzfw5rn","updated":"20230817161866"},"Children":[{"Type":"NodeText","Data":"WAL最重要的作用是灾难恢复。和MySQL 的Binlog类似，它记录所有的数据改动。一旦服务器崩溃，通过重放log可以恢复崩溃之前的数据。这也就意味如果写入WAL失败，整个写入操作将认为失败。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"HBase中，HLog是WAL的实现类。一个HRegionServer对应一个HLog实例。"}]},{"ID":"20230817161867-uskhk53","Type":"NodeParagraph","Properties":{"id":"20230817161867-uskhk53","updated":"20230817161867"},"Children":[{"Type":"NodeText","Data":"WAL数据是存储在HDFS上面的，点进去可以看到是一个一个的文件。"}]},{"ID":"20230817161868-bxxhpds","Type":"NodeParagraph","Properties":{"id":"20230817161868-bxxhpds","updated":"20230817161868"},"Children":[{"Type":"NodeText","Data":"采用这种模式，可以保证HRegionServer宕机后，我们依然可以从该log文件中恢复数据，而不至于数据丢失。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"主要是因为数据写入到Memstore中，这个是基于内存的，如果节点宕机了，内存中的数据就没了，这个时候可以通过WAL恢复数据。如果数据从Memstore 持久化到HFile之后，其实就不需要WAL日志了。所以WAL日志不会保存所有的操作，只会保留一部分，这个日志也会有一个删除策略。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"WAL这个日志文件会定期生成新的文件而删除旧的文件(那些已持久化到HFile中的数据对应的日志可以删除)。"}]},{"ID":"20230817161869-rufhh85","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161869-rufhh85","updated":"20230817161869"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"HFile介绍"}]},{"ID":"20230817161870-be4kiq6","Type":"NodeParagraph","Properties":{"id":"20230817161870-be4kiq6","updated":"20230817161870"},"Children":[{"Type":"NodeText","Data":"HFile是HBase中重要的一个存在，可以说是HBase架构中最小的结构，HBase的底层数据都在HFile中。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"HFile从根本上来说是HDFS中的文件，只是它有自己特殊的格式。"}]},{"ID":"20230817161871-bw5b4nr","Type":"NodeParagraph","Properties":{"id":"20230817161871-bw5b4nr","updated":"20230817161871"},"Children":[{"Type":"NodeText","Data":"HFile文件由6部分组成："}]},{"ID":"20230817161872-117sq1m","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20230817161872-117sq1m","updated":"20230817161872"},"Children":[{"ID":"20230817161873-p6dxp39","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20230817161873-p6dxp39","updated":"20230817161873"},"Children":[{"ID":"20230817161874-5vkab82","Type":"NodeParagraph","Properties":{"id":"20230817161874-5vkab82","updated":"20230817161874"},"Children":[{"Type":"NodeText","Data":"Data(数据块): 保存表中的数据(key-value的形式)，这部分可以被压缩，每个数据块都有一个Magic头,负责存储偏移量和第一个Key。"}]}]},{"ID":"20230817161875-pzp864l","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20230817161875-pzp864l","updated":"20230817161875"},"Children":[{"ID":"20230817161876-lis0phe","Type":"NodeParagraph","Properties":{"id":"20230817161876-lis0phe","updated":"20230817161876"},"Children":[{"Type":"NodeText","Data":"Meta(元数据块)：存储用户自定义的key-value。"}]}]},{"ID":"20230817161877-v0ittql","Type":"NodeListItem","Data":"3","ListData":{"Typ":1,"Tight":true,"Start":3,"Delimiter":46,"Padding":3,"Marker":"Mw==","Num":3},"Properties":{"id":"20230817161877-v0ittql","updated":"20230817161877"},"Children":[{"ID":"20230817161878-tu8qaty","Type":"NodeParagraph","Properties":{"id":"20230817161878-tu8qaty","updated":"20230817161878"},"Children":[{"Type":"NodeText","Data":"File Info：定长，记录了文件的一些元信息，例如：AVG_KEY_LEN，AVG_VALUE_LEN，LAST_KEY等"}]}]},{"ID":"20230817161879-obodptt","Type":"NodeListItem","Data":"4","ListData":{"Typ":1,"Tight":true,"Start":4,"Delimiter":46,"Padding":3,"Marker":"NA==","Num":4},"Properties":{"id":"20230817161879-obodptt","updated":"20230817161879"},"Children":[{"ID":"20230817161880-ro5n2rr","Type":"NodeParagraph","Properties":{"id":"20230817161880-ro5n2rr","updated":"20230817161880"},"Children":[{"Type":"NodeText","Data":"Data Index(数据块索引)：记录了每个数据块（Data）的起始索引。"}]}]},{"ID":"20230817161881-lj9rbh9","Type":"NodeListItem","Data":"5","ListData":{"Typ":1,"Tight":true,"Start":5,"Delimiter":46,"Padding":3,"Marker":"NQ==","Num":5},"Properties":{"id":"20230817161881-lj9rbh9","updated":"20230817161881"},"Children":[{"ID":"20230817161882-z35uqo6","Type":"NodeParagraph","Properties":{"id":"20230817161882-z35uqo6","updated":"20230817161882"},"Children":[{"Type":"NodeText","Data":"Meta Index(元数据块索引)：记录了每个元数据块（Meta）的起始索引。"}]}]},{"ID":"20230817161883-2qgx38e","Type":"NodeListItem","Data":"6","ListData":{"Typ":1,"Tight":true,"Start":6,"Delimiter":46,"Padding":3,"Marker":"Ng==","Num":6},"Properties":{"id":"20230817161883-2qgx38e","updated":"20230817161883"},"Children":[{"ID":"20230817161884-poi56vg","Type":"NodeParagraph","Properties":{"id":"20230817161884-poi56vg","updated":"20230817161884"},"Children":[{"Type":"NodeText","Data":"Trailer：定长，用于指向其他数据块的起始点。"}]}]}]},{"ID":"20230817161885-lcsoa2w","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161885-lcsoa2w","updated":"20230817161885"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"BloomFilter布隆过滤器"}]},{"ID":"20230817161886-annew3w","Type":"NodeParagraph","Properties":{"id":"20230817161886-annew3w","updated":"20230817161886"},"Children":[{"Type":"NodeText","Data":"布隆过滤器是一种比较巧妙的概率型数据结构，可以用来告诉你 “某样东西一定不存在或者可能存在”。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"也就是说它告诉你某样东西不存在的话就一定不存在。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"如果它告诉你某样东西存在，也可能实际是不存在的。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"布隆过滤器是hbase中的高级功能，它能够减少特定访问模式（get/scan）下的查询时间。进而提高HBase集群的吞吐率。"}]},{"ID":"20230817161887-lxb4xw3","Type":"NodeParagraph","Properties":{"id":"20230817161887-lxb4xw3","updated":"20230817161887"},"Children":[{"Type":"NodeText","Data":"当我们随机查询数据时，如果采用HBase的块索引机制，HBase会加载很多块文件。如果采用布隆过滤器后，它能够准确判断该HFile的所有数据块中，是否含有我们查询的数据，从而大大减少不必要的块加载，进而提高HBase集群的吞吐率。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"对于HBase而言，当我们选择采用布隆过滤器之后，HBase会在生成HFile时包含一份布隆过滤器结构的数据，开启布隆过滤器会有一定的存储及内存开销。但是在大多数情况下，这些负担相对于布隆过滤器带来的好处来说是可以接受的。"}]},{"ID":"20230817161888-yrbgnep","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161888-yrbgnep","updated":"20230817161888"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"HFile compaction（合并）机制"}]},{"ID":"20230817161889-vwx4tg6","Type":"NodeParagraph","Properties":{"id":"20230817161889-vwx4tg6","updated":"20230817161889"},"Children":[{"Type":"NodeText","Data":"当MemStore超过阀值的时候，就会持久化生成一个（StoreFile）HFile。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"因此随着数据不断写入，HFile的数量将会越来越多，HFile数量过多会降低读性能，因为每次查询数据都需要加载多个HFile文件。为了避免对读性能的影响，可以对这些HFile进行合并操作，把多个HFile合并成一个HFile。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"合并操作需要对HBase中的数据进行多次的重新读写，这个过程会产生大量的IO。因此可以发现合并机制的本质就是以IO操作换取后续读性能的提高。"}]},{"ID":"20230817161890-xq10ymx","Type":"NodeParagraph","Properties":{"id":"20230817161890-xq10ymx","updated":"20230817161890"},"Children":[{"Type":"NodeText","Data":"合并操作分为major（大合并）和minor（小合并）两种。"}]},{"ID":"20230817161891-g75mx1s","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161891-g75mx1s","updated":"20230817161891"},"Children":[{"ID":"20230817161892-uv3mbc0","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161892-uv3mbc0","updated":"20230817161892"},"Children":[{"ID":"20230817161893-ox90t5z","Type":"NodeParagraph","Properties":{"id":"20230817161893-ox90t5z","updated":"20230817161893"},"Children":[{"Type":"NodeText","Data":"minor（小合并）：只做部分文件的合并操作，生成新文件设置成激活状态，然后删除老的HFile文件。小合并的过程一般较快，而且IO相对较低。"}]}]},{"ID":"20230817161894-e8tp8a9","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161894-e8tp8a9","updated":"20230817161894"},"Children":[{"ID":"20230817161895-sahaeyx","Type":"NodeParagraph","Properties":{"id":"20230817161895-sahaeyx","updated":"20230817161895"},"Children":[{"Type":"NodeText","Data":"major（大合并）：对Region下的所有HFile执行合并操作，最终的结果是合并出一个HFile文件。在生成新的HFile时，会忽略掉已经标记为删除的数据、ttl过期的数据、版本超过限定的数据。大合并会产生大量的IO操作，对HBase的读写性能产生较大影响。"}]}]}]},{"ID":"20230817161896-limd9dt","Type":"NodeBlockquote","Properties":{"id":"20230817161896-limd9dt","updated":"20230817161896"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20230817161897-hbbjlrb","Type":"NodeParagraph","Properties":{"id":"20230817161897-hbbjlrb","updated":"20230817161897"},"Children":[{"Type":"NodeText","Data":"注意：一般情况下，大合并会持续很长时间，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会关闭自动触发大合并功能，改为手动在业务低峰期触发。"}]}]},{"ID":"20230817161898-rvatiwc","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161898-rvatiwc","updated":"20230817161898"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Region Split（分裂）机制"}]},{"ID":"20230817161899-t07t7i0","Type":"NodeParagraph","Properties":{"id":"20230817161899-t07t7i0","updated":"20230817161899"},"Children":[{"Type":"NodeText","Data":"前面我们分析了HFile文件的合并机制，当HFile文件合并多次之后，会导致Region中的数据过大，此时就需要涉及Region的分裂机制了。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"当HBase中的一个表刚被创建的时候，HBase默认只会分配一个Region给这个表。也就是说这个时候，所有的读写请求都会访问到同一个RegionServer中的同一个Region中，出现读写热点问题。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"并且当 Region管理的数据量过多，或 HFile 文件较大时，都会影响性能。"}]},{"ID":"20230817161900-fst7var","Type":"NodeParagraph","Properties":{"id":"20230817161900-fst7var","updated":"20230817161900"},"Children":[{"Type":"NodeText","Data":"为了达到负载均衡，当Region达到一定的大小时就会将一个Region分裂成两个新的子 Region，并对父 Region 进行清除处理。"}]},{"ID":"20230817161901-r4ugz0y","Type":"NodeParagraph","Properties":{"id":"20230817161901-r4ugz0y","updated":"20230817161901"},"Children":[{"Type":"NodeText","Data":"HMaster会根据Balance策略，重新分配Region所属的RegionServer，最大化的发挥分布式系统的优点。"}]},{"ID":"20230817161902-1qa5vyo","Type":"NodeParagraph","Properties":{"id":"20230817161902-1qa5vyo","updated":"20230817161902"},"Children":[{"Type":"NodeText","Data":"触发Region Split的条件："}]},{"ID":"20230817161903-9l9n1k6","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161903-9l9n1k6","updated":"20230817161903"},"Children":[{"ID":"20230817161904-m23zvfn","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161904-m23zvfn","updated":"20230817161904"},"Children":[{"ID":"20230817161905-43ndmhk","Type":"NodeParagraph","Properties":{"id":"20230817161905-43ndmhk","updated":"20230817161905"},"Children":[{"Type":"NodeText","Data":"ConstantSizeRegionSplitPolicy （0.94版本前）："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"一个Region 中最大 HFile文件的大小大于设置的阈值（hbase.hregion.max.filesize）之后才会触发切分，HFile文件大小为压缩后的文件大小（针对启用压缩的场景），默认文件大小的阈值为10G。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"这种策略简单粗暴，但是弊端相当大。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"阈值设置偏大的话，对大表友好，小表可能不会触发分裂，极端情况下小表可能就只会有一个Region。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"阈值设置偏小的话，对小表友好，但一个大表可能会在集群中产生大量的Region，对于集群管理来说不是好事。"}]}]},{"ID":"20230817161906-tzwse83","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161906-tzwse83","updated":"20230817161906"},"Children":[{"ID":"20230817161907-0pfly99","Type":"NodeParagraph","Properties":{"id":"20230817161907-0pfly99","updated":"20230817161907"},"Children":[{"Type":"NodeText","Data":"IncreasingToUpperBoundRegionSplitPolicy （0.94版本~2.x版本默认切分策略）："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"一个Region中最大 HFile文件的大小大于设置的阈值就会触发切分，区别是这个阈值并不像 ConstantSizeRegionSplitPolicy是一个固定的值，这里的阈值是会不断调整的。调整规则和 Region所属表在当前 RegionServer上的 Region个数有关系 。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"公式："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"调整后的阈值 = Region个数的3次方 * flush_size * 2"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"注意：这里的阈值不会无限增大，会通过hbase.hregion.max.filesize来进行限制，不能超过这个参数的大小。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"这种策略能够自适应大小表，集群规模大的情况下，对大表很优秀，对小表会产生大量小Region（比第一种策略好一些）。"}]}]}]},{"ID":"20230817161908-vrcedna","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161908-vrcedna","updated":"20230817161908"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Region Balance(负载均衡策略)"}]},{"ID":"20230817161909-wh1sej3","Type":"NodeParagraph","Properties":{"id":"20230817161909-wh1sej3","updated":"20230817161909"},"Children":[{"Type":"NodeText","Data":"Region分裂之后就会涉及到Region的负载均衡。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"HBase的HMaster进程会自动根据指定策略挑选出一些Region，并将这些Region分配到负载比较低的RegionServer上。"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"由于HBase的所有数据都是写入到HDFS文件系统中的， 因此HBase的Region移动其实是非常轻量级。在做Region移动的时候，保持这个Region对应的HDFS文件位置不变，只需要将Region的元数据分配到对应的RegionServer中即可。"}]},{"ID":"20230817161910-8uu5mi5","Type":"NodeParagraph","Properties":{"id":"20230817161910-8uu5mi5","updated":"20230817161910"},"Children":[{"Type":"NodeText","Data":"官方目前支持两种挑选Region的策略："},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultLoadBalancer"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"StochasticLoadBalancer"},{"Type":"NodeText","Data":"。"}]},{"ID":"20230817161911-eke2i3f","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161911-eke2i3f","updated":"20230817161911"},"Children":[{"ID":"20230817161912-axrhsj9","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161912-axrhsj9","updated":"20230817161912"},"Children":[{"ID":"20230817161913-kxuzwiv","Type":"NodeParagraph","Properties":{"id":"20230817161913-kxuzwiv","updated":"20230817161913"},"Children":[{"Type":"NodeText","Data":"DefaultLoadBalancer：这种策略能够保证每个RegionServer中的Region个数基本上都相等。"}]}]},{"ID":"20230817161914-w915cp1","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161914-w915cp1","updated":"20230817161914"},"Children":[{"ID":"20230817161915-rgf3c2w","Type":"NodeParagraph","Properties":{"id":"20230817161915-rgf3c2w","updated":"20230817161915"},"Children":[{"Type":"NodeText","Data":"StochasticLoadBalancer ：这种策略非常复杂，简单来讲是一种综合权衡6个因素的均衡策略。"}]}]}]},{"ID":"20230817161916-7roc2a5","Type":"NodeParagraph","Properties":{"id":"20230817161916-7roc2a5","updated":"20230817161916"},"Children":[{"Type":"NodeText","Data":"采用6个因素加权的方式算出一个代价值，这个代价值用来评估当前Region分布是否均衡，越均衡代价值越低。"}]},{"ID":"20230817161917-ywyagp9","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161917-ywyagp9","updated":"20230817161917"},"Children":[{"ID":"20230817161918-w6b0l25","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161918-w6b0l25","updated":"20230817161918"},"Children":[{"ID":"20230817161919-7sxp4n4","Type":"NodeParagraph","Properties":{"id":"20230817161919-7sxp4n4","updated":"20230817161919"},"Children":[{"Type":"NodeText","Data":"每台服务器读请求数(ReadRequestCostFunction)"}]}]},{"ID":"20230817161920-4zteysq","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161920-4zteysq","updated":"20230817161920"},"Children":[{"ID":"20230817161921-t7kpihv","Type":"NodeParagraph","Properties":{"id":"20230817161921-t7kpihv","updated":"20230817161921"},"Children":[{"Type":"NodeText","Data":"每台服务器写请求数(WriteRequestCostFunction)"}]}]},{"ID":"20230817161922-er9vlkx","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161922-er9vlkx","updated":"20230817161922"},"Children":[{"ID":"20230817161923-ei3hz4u","Type":"NodeParagraph","Properties":{"id":"20230817161923-ei3hz4u","updated":"20230817161923"},"Children":[{"Type":"NodeText","Data":"Region个数(RegionCountSkewCostFunction)"}]}]},{"ID":"20230817161924-hkwcmjh","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161924-hkwcmjh","updated":"20230817161924"},"Children":[{"ID":"20230817161925-5hott63","Type":"NodeParagraph","Properties":{"id":"20230817161925-5hott63","updated":"20230817161925"},"Children":[{"Type":"NodeText","Data":"移动代价(MoveCostFunction)"}]}]},{"ID":"20230817161926-tiljyl9","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161926-tiljyl9","updated":"20230817161926"},"Children":[{"ID":"20230817161927-50jlpe1","Type":"NodeParagraph","Properties":{"id":"20230817161927-50jlpe1","updated":"20230817161927"},"Children":[{"Type":"NodeText","Data":"数据Locality(TableSkewCostFunction)"}]}]},{"ID":"20230817161928-2lmh33r","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20230817161928-2lmh33r","updated":"20230817161928"},"Children":[{"ID":"20230817161929-qo129z8","Type":"NodeParagraph","Properties":{"id":"20230817161929-qo129z8","updated":"20230817161929"},"Children":[{"Type":"NodeText","Data":"每张表占据RegionServer中Region个数上限(LocalityCostFunction)"}]}]}]}]}