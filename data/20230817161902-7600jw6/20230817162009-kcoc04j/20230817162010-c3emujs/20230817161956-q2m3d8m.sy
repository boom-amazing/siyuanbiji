{"ID":"20230817161956-q2m3d8m","Spec":"1","Type":"NodeDocument","Properties":{"id":"20230817161956-q2m3d8m","title":"kafak相关问题","updated":"20230817161956"},"Children":[{"ID":"20230817161957-2ebxg53","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20230817161957-2ebxg53","updated":"20230817161957"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"kafak相关问题："}]},{"ID":"20230817161958-acunj09","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161958-acunj09","updated":"20230817161958"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"请思考一下为什么 Kafka 不像 MySQL 那样允许追随者副本对外提供读服务？"}]},{"ID":"20230817161959-wevkhwf","Type":"NodeParagraph","Properties":{"id":"20230817161959-wevkhwf","updated":"20230817161959"},"Children":[{"Type":"NodeText","Data":"mysql让副本对外提供服务(主写从读)无非就是减少主节点的压力，而kafak的分布式存储 如果partition分布的比较均匀 每次从主节点读取数据也可以很好的达到负载均衡"}]},{"ID":"20230817161960-nlmtnvo","Type":"NodeParagraph","Properties":{"id":"20230817161960-nlmtnvo","updated":"20230817161960"},"Children":[{"Type":"NodeText","Data":"如果强行让从节点也对外提供服务 从生产者角度看 如果消息还没有从leader节点同步到flower节点就已经开始读 可能会导致数据不一致的问题  从消费者的角度看 每次读都要记录一个消费者的offeset 这里就还需要维护flowe的offeset 那么会增减程序设计的复杂性"}]},{"ID":"20230817161961-prmc616","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161961-prmc616","updated":"20230817161961"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"怎么保证kafak的高可用？"}]},{"ID":"20230817161962-znldcyf","Type":"NodeParagraph","Properties":{"id":"20230817161962-znldcyf","updated":"20230817161962"},"Children":[{"Type":"NodeText","Data":"一是kafak自身提供了副本机制 当一个broker宕机后  通过zookeeper可以重写给分区选择leader   生产者和消费者可以重新在其他机器上继续运行程序  极大地提高了容错性"}]},{"ID":"20230817161963-ope9jg7","Type":"NodeParagraph","Properties":{"id":"20230817161963-ope9jg7","updated":"20230817161963"},"Children":[{"Type":"NodeText","Data":"二是如果消费者的某个线程挂掉 导致当前的消费者所消费的分区无法消费 那么kafak会在消费者组里面实现重平衡的策略 让挂掉的消费者所运行的线程被其他活着的消费者所消费"}]},{"ID":"20230817161964-3lemlxz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20230817161964-3lemlxz","updated":"20230817161964"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"##### ","Properties":{"id":""}},{"Type":"NodeText","Data":"kafak如何保证数据不丢？"}]},{"ID":"20230817161965-jk1rrqa","Type":"NodeParagraph","Properties":{"id":"20230817161965-jk1rrqa","updated":"20230817161965"},"Children":[{"Type":"NodeText","Data":"生产者：（producer-\u003ekafak）"}]},{"ID":"20230817161966-yfya3uh","Type":"NodeParagraph","Properties":{"id":"20230817161966-yfya3uh","updated":"20230817161966"},"Children":[{"Type":"NodeText","Data":"通过acks机制保证的 如果将acks设置为all的话 就需要等待对应partition所在的所有leader和flower都确认收到消息后才会认为数据是发送成功了 在这种策略下 数据不会丢失 。"}]},{"ID":"20230817161967-sgek4eq","Type":"NodeParagraph","Properties":{"id":"20230817161967-sgek4eq","updated":"20230817161967"},"Children":[{"Type":"NodeText","Data":"如果只将acks设置为1 则只通过leader确认消息 如果leader宕机 flower还没用同步消息 这样就无法保证数据不丢失"}]},{"ID":"20230817161968-5g802yk","Type":"NodeParagraph","Properties":{"id":"20230817161968-5g802yk","updated":"20230817161968"},"Children":[{"Type":"NodeText","Data":"还可以将其设置为0 就是不管有没有确认消息 他都继续发送消息 这样丢失消息可能性极高"}]},{"ID":"20230817161969-dm47hdd","Type":"NodeParagraph","Properties":{"id":"20230817161969-dm47hdd","updated":"20230817161969"},"Children":[{"Type":"NodeText","Data":"消费者：（Kafka -\u003e consumer）"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"通过消费者offset commit使用at-least-once或exactly-once语义对数据进行处理，at-least-once在消息处理逻辑后手动提交offset，可能会导致宕机导致下一次处理时重复处理；exactly-once将数据处理结果与offset结果绑定，当数据处理成功后提交offset。两者方式均可保证Kafka-\u003e消费者时数据不丢失。"}]}]}