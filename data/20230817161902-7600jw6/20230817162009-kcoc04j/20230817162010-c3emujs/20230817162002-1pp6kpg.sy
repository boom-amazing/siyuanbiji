{"ID":"20230817162002-1pp6kpg","Spec":"1","Type":"NodeDocument","Properties":{"id":"20230817162002-1pp6kpg","title":"kafka与flume结合构建实时处理与离线处理","updated":"20230817162002"},"Children":[{"ID":"20230817162003-w7zvczm","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20230817162003-w7zvczm","updated":"20230817162003"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"kafka与flume结合构建实时处理与离线处理"}]},{"ID":"20230817162004-r3mzawn","Type":"NodeParagraph","Properties":{"id":"20230817162004-r3mzawn","updated":"20230817162004"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"图片描述","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://img.mukewang.com/wiki/5f5e05f809bb9b0a12670523.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20230817162005-m1h3ypd","Type":"NodeParagraph","Properties":{"id":"20230817162005-m1h3ypd","updated":"20230817162005"},"Children":[{"Type":"NodeText","Data":"图中的kafka集群不但可以做实时的处理 也可以用作离线处理存入hdfs kafak 在实时和离线都有用途"}]},{"ID":"20230817162006-1bk01es","Type":"NodeParagraph","Properties":{"id":"20230817162006-1bk01es","updated":"20230817162006"},"Children":[{"Type":"NodeText","Data":"下面使用flume采集数据到kafka 再用flume将kafka的数据导入hdfs"}]},{"ID":"20230817162007-6r630cu","Type":"NodeParagraph","Properties":{"id":"20230817162007-6r630cu","updated":"20230817162007"},"Children":[{"Type":"NodeText","Data":"配置两个agent 第一个为 file-to-kafka 第二个为kafka-to-hdfs"}]},{"ID":"20230817162008-xohpp9l","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"c2hlbGw=","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817162008-xohpp9l","updated":"20230817162008"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"c2hlbGw=","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"# Name the components on this agent\na1.sources = r1\na1.channels = c1\na1.sinks = k1\n\n\n# Describe/configure the source\na1.sources.r1.type = exec\na1.sources.r1.command = tail -F /data/log/test.log\n\n\n# Use a channel which buffers events in memory\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n\n# Describe the sink\na1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink\na1.sinks.k1.kafka.topic = test_r2p5\na1.sinks.k1.kafka.bootstrap.servers = bigdata01:9092,bigdata02:9092,bigdata03:9092\na1.sinks.k1.kafka.flumeBatchSize = 1\na1.sinks.k1.kafka.producer.acks = 1\na1.sinks.k1.kafka.producer.linger.ms = 1\na1.sinks.k1.kafka.producer.compression.type = snappy//这里代表生产者 所以kafka的生产者的配置都可以在这里设定\n\n# Bind the source and sink to the channel\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1\n\n\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20230817162009-wp73o9p","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"c2hlbGw=","CodeBlockCloseFence":"YGBg","Properties":{"id":"20230817162009-wp73o9p","updated":"20230817162009"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"c2hlbGw=","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"\n\n# Name the components on this agent\na1.sources = r1\na1.channels = c1\na1.sinks = k1\n\n\n# Describe/configure the source\na1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource\na1.sources.r1.batchSize = 1\na1.sources.r1.batchDurationMillis = 2000\na1.sources.r1.kafka.bootstrap.servers = bigdata01:9092,bigdata02:9092,bigdata03:9092\na1.sources.r1.kafka.topics = test_r2p5\na1.sources.r1.kafka.consumer.group.id = flume-con1//需要指定消费者组\n\n\n# Use a channel which buffers events in memory\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n\n# Describe the sink\na1.sinks.k1.type = hdfs\na1.sinks.k1.hdfs.path = hdfs://192.168.93.100:9000/kafkaout\na1.sinks.k1.hdfs.filePrefix = data-\na1.sinks.k1.hdfs.writeFormat=Text\na1.sinks.k1.hdfs.fileType=DataStream\na1.sinks.k1.hdfs.rollInterval=3600\na1.sinks.k1.hdfs.rollSize=134217728\na1.sinks.k1.hdfs.rollCount=0\n\n# Bind the source and sink to the channel\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1\n\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]}]}